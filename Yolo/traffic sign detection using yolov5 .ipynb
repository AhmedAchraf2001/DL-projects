{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T20:21:59.297321Z",
     "start_time": "2022-10-20T20:21:59.293329Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch # YOLOv5 implemented using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T20:21:59.352170Z",
     "start_time": "2022-10-20T20:21:59.298314Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image #this is to render predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide the dataset in train and val folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T20:56:03.634823Z",
     "start_time": "2022-10-20T20:56:03.626844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images are :  592\n",
      "Validation images are :  148\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import choice\n",
    "import shutil\n",
    "\n",
    "#arrays to store file names\n",
    "imgs =[]\n",
    "xmls =[]\n",
    "\n",
    "#setup dir names\n",
    "trainPath = 'X:/AI/projects/Yolo/dataset/images/train'\n",
    "valPath = 'X:/AI/projects/Yolo/dataset/images/val'\n",
    "crsPath = 'ts/ts/' #dir where images and annotations stored\n",
    "\n",
    "#setup ratio (val ratio = rest of the files in origin dir after splitting into train and test)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "#total count of imgs\n",
    "totalImgCount = len(os.listdir(crsPath))/2\n",
    "\n",
    "#soring files to corresponding arrays\n",
    "for (dirname, dirs, files) in os.walk(crsPath):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            xmls.append(filename)\n",
    "        else:\n",
    "            imgs.append(filename)\n",
    "\n",
    "\n",
    "#counting range for cycles\n",
    "countForTrain = int(len(imgs)*train_ratio)\n",
    "countForVal = int(len(imgs)*val_ratio)\n",
    "print(\"training images are : \",countForTrain)\n",
    "print(\"Validation images are : \",countForVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T20:56:05.481099Z",
     "start_time": "2022-10-20T20:56:04.497574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X:/AI/projects/Yolo/dataset/images/val\\\\ts'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainimagePath = 'X:/AI/projects/Yolo/dataset/images/train'\n",
    "trainlabelPath = 'X:/AI/projects/Yolo/dataset/labels/train'\n",
    "valimagePath = 'X:/AI/projects/Yolo/dataset/images/val'\n",
    "vallabelPath = 'X:/AI/projects/Yolo/dataset/labels/val'\n",
    "#cycle for train dir\n",
    "for x in range(countForTrain):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "\n",
    "\n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "\n",
    "\n",
    "#cycle for test dir   \n",
    "for x in range(countForVal):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    \n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "#rest of files will be validation files, so rename origin dir to val dir\n",
    "#os.rename(crsPath, valPath)\n",
    "shutil.move(crsPath, valPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T21:18:45.034127Z",
     "start_time": "2022-10-20T21:16:43.904445Z"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py --img 415 --batch 16 --epochs 30 --data dataset.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T21:16:14.499554Z",
     "start_time": "2022-10-20T21:16:09.616068Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['best.pt'], source=runs/train/exp2/a.jpg, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  2022-10-20 Python-3.9.7 torch-1.12.1+cpu CPU\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"X:\\AI\\projects\\Yolo\\detect.py\", line 258, in <module>\n",
      "    main(opt)\n",
      "  File \"X:\\AI\\projects\\Yolo\\detect.py\", line 253, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\10\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"X:\\AI\\projects\\Yolo\\detect.py\", line 95, in run\n",
      "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
      "  File \"X:\\AI\\projects\\Yolo\\models\\common.py\", line 342, in __init__\n",
      "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
      "  File \"X:\\AI\\projects\\Yolo\\models\\experimental.py\", line 79, in attempt_load\n",
      "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "  File \"C:\\Users\\10\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"C:\\Users\\10\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"C:\\Users\\10\\anaconda3\\lib\\site-packages\\torch\\serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'best.pt'\n"
     ]
    }
   ],
   "source": [
    "#!python detect.py --source runs/train/exp/testimg.jpg --weights runs/train/exp/weights/best.pt --conf 0.25\n",
    "\n",
    "!python detect.py --source runs/train/exp2/a.jpg --weights best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
